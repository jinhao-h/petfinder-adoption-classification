{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling PetFinder.my with Logistic Regression\n",
    "\n",
    "Model: (Multinomial) Logistic Regression.\n",
    "\n",
    "Evaluation metric: Quadratic Kappa\n",
    "\n",
    "## References\n",
    "\n",
    "* [Mathematical Explanation of Naive Bayes](https://towardsdatascience.com/a-mathematical-explanation-of-naive-bayes-in-5-minutes-44adebcdb5f8/)\n",
    "* [Gaussian NB Guide](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.GaussianNB.html#sklearn.naive_bayes.GaussianNB)\n",
    "* [Multinomial NB Guide](https://scikit-learn.org/stable/modules/generated/sklearn.naive_bayes.MultinomialNB.html#sklearn.naive_bayes.MultinomialNB)\n",
    "* [Naive Bayes: A Baseline Model Guide](https://www.kdnuggets.com/2019/04/naive-bayes-baseline-model-machine-learning-classification-performance.html/2)\n",
    "* [Multinomial Naive Bayes Classifier for Text Analysis](https://towardsdatascience.com/multinomial-naive-bayes-classifier-for-text-analysis-python-8dd6825ece67)\n",
    "* [Naive Bayes Classification using Scikit-learn](https://www.datacamp.com/community/tutorials/naive-bayes-scikit-learn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.naive_bayes import MultinomialNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.max_rows', None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "SOURCE_DATA_FOLDER = \"../data/source/petfinder-adoption-prediction/\"\n",
    "TRAIN_IMAGE_FOLDER = SOURCE_DATA_FOLDER + \"train_images/\"\n",
    "TRAIN_METADATA_FOLDER = SOURCE_DATA_FOLDER + \"train_metadata/\"\n",
    "TRAIN_SENTIMENT_FOLDER = SOURCE_DATA_FOLDER + \"train_sentiment/\"\n",
    "\n",
    "BREED_LABELS = SOURCE_DATA_FOLDER + \"breed_labels.csv\"\n",
    "COLOR_LABELS = SOURCE_DATA_FOLDER + \"color_labels.csv\"\n",
    "STATE_LABELS = SOURCE_DATA_FOLDER + \"state_labels.csv\"\n",
    "TRAIN_TABULAR = SOURCE_DATA_FOLDER + \"train/train.csv\"\n",
    "TEST_TABULAR = SOURCE_DATA_FOLDER + \"test/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_tabular_df = pd.read_csv(TRAIN_TABULAR)\n",
    "test_tabular_df = pd.read_csv(TEST_TABULAR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocessing(df):\n",
    "\n",
    "    transformed_df = df.copy()\n",
    "\n",
    "    # Change Name to 1 - has name, 0 - has no name\n",
    "    transformed_df['Name'] = transformed_df['Name'].fillna(0)\n",
    "    transformed_df['Name'].replace({\"No Name\": 0, \"No Name Yet\": 0, \"Unknown\": 0},inplace=True)\n",
    "    transformed_df.loc[transformed_df['Name'] !=0, 'Name'] = 1\n",
    "\n",
    "    # Create age bins\n",
    "    age_bins = pd.cut(transformed_df['Age'], bins=[0,3,6,12,24,300], include_lowest=True)\n",
    "    age_bin_dummies = pd.get_dummies(age_bins)\n",
    "    age_bin_dummies.columns = [\"is_age_0_3\", \"is_age_3_6\", \"is_age_6_12\",\"is_age_12_24\", \"is_age_24_300\"]\n",
    "    transformed_df = pd.concat([transformed_df, age_bin_dummies], axis=1)\n",
    "\n",
    "    # One-hot encode dummy variables\n",
    "    dummy_cols = [\n",
    "        'Type',\n",
    "        'Gender',\n",
    "        'MaturitySize',\n",
    "        'Vaccinated',\n",
    "        'Dewormed',\n",
    "        'Sterilized',\n",
    "        'Health',\n",
    "        'FurLength',\n",
    "        'State',\n",
    "        'Breed1',\n",
    "        'Breed2',\n",
    "        'Color1',\n",
    "        'Color2',\n",
    "        'Color3',\n",
    "    ]\n",
    "\n",
    "    transformed_df = pd.get_dummies(transformed_df, columns=dummy_cols)\n",
    "    \n",
    "    # Get rid of all non-encoded columns except Quantity\n",
    "    transformed_df.drop(columns=[\"VideoAmt\", \"PhotoAmt\", \"RescuerID\", \"Description\", \"PetID\", \"Age\", \"Fee\"], \n",
    "                        inplace=True)\n",
    "    \n",
    "    return transformed_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Final model: Multinomial NB with One-Hot Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "first_train = preprocessing(train_tabular_df)\n",
    "first_test = preprocessing(test_tabular_df)\n",
    "first_test[\"AdoptionSpeed\"] = None\n",
    "train, test = first_train.align(first_test, join='inner', axis=1)\n",
    "test.drop(columns=[\"AdoptionSpeed\"], inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = train.drop(columns=[\"AdoptionSpeed\"])\n",
    "y_train = train[\"AdoptionSpeed\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    5.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
       "                                     fit_prior=True),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'alpha': [0.01, 0.1, 0.5, 1.0, 10.0]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(cohen_kappa_score, weights=quadratic),\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now do GridSearchCV on the model\n",
    "params = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0, ], }\n",
    "quadratic_kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "grid = GridSearchCV(MultinomialNB(), params, refit = True, verbose = True, scoring=quadratic_kappa_scorer)\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.01}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training score: 0.29174263004198075\n"
     ]
    }
   ],
   "source": [
    "# Run through model\n",
    "clf = MultinomialNB(alpha=0.1)\n",
    "clf.fit(X_train, y_train)\n",
    "y_pred = clf.predict(test)\n",
    "\n",
    "print(\"Training score:\", cohen_kappa_score(clf.predict(X_train), y_train, weights='quadratic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(3972, 2)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PetID</th>\n",
       "      <th>AdoptionSpeed</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>e2dfc2935</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>f153b465f</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3c90f3f54</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>e02abc8a3</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>09f0df7d1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       PetID  AdoptionSpeed\n",
       "0  e2dfc2935              2\n",
       "1  f153b465f              4\n",
       "2  3c90f3f54              1\n",
       "3  e02abc8a3              4\n",
       "4  09f0df7d1              4"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission = pd.DataFrame.from_dict({'PetID': test_tabular_df['PetID'],\n",
    "                                     'AdoptionSpeed': y_pred})\n",
    "print(submission.shape)\n",
    "submission.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission.to_csv(\"../data/final/jinhao-submission.csv\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## ALL ROUGH TESTING/WORKING CODE BELOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import cohen_kappa_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import make_scorer\n",
    "from scipy import stats\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.metrics import classification_report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(TRAIN_TABULAR)\n",
    "\n",
    "# Cleaning\n",
    "# Add quantity of RescuerID\n",
    "train_df[\"RescuerID_count\"] = train_df.groupby(\"RescuerID\")[\"RescuerID\"].transform(\"count\")\n",
    "# sns.countplot(x=\"RescuerID_count\", data=train_processed)\n",
    "# plt.title(\"RescuerID Count Distribution\")\n",
    "\n",
    "# Change Name to 1 - has name, 0 - has no name\n",
    "train_df['Name'] = train_df['Name'].fillna(0)\n",
    "train_df['Name'].replace({\"No Name\": 0, \"No Name Yet\": 0, \"Unknown\": 0},inplace=True)\n",
    "train_df.loc[train_df['Name'] !=0, 'Name'] = 1\n",
    "\n",
    "# Outlier removal\n",
    "train_df = train_df[(np.abs(stats.zscore(train_df['Age'])) < 3)]\n",
    "train_df = train_df[(np.abs(stats.zscore(train_df['PhotoAmt'])) < 3)]\n",
    "train_df = train_df[(np.abs(stats.zscore(train_df['Quantity'])) < 3)]\n",
    "\n",
    "# Normalise numerical columns\n",
    "columns_to_normalize = ['Age', 'MaturitySize', 'FurLength', 'Quantity', 'PhotoAmt', 'Fee', 'VideoAmt']\n",
    "x = train_df[columns_to_normalize].values\n",
    "scaler = MinMaxScaler()\n",
    "x_scaled = scaler.fit_transform(x)\n",
    "train_temp = pd.DataFrame(x_scaled, columns=columns_to_normalize, index=train_df.index)\n",
    "train_df[columns_to_normalize] = train_temp\n",
    "\n",
    "# Get rid of unused columns\n",
    "data_all = train_df.drop(columns=[\"RescuerID\", \"Description\", \"PetID\"])\n",
    "\n",
    "# Consider removing non-categorical rows -> Age, Quantity, Fee, RescuerID_count, VideoAmt, PhotoAmt\n",
    "data_categorical = train_df.drop(columns=[\"RescuerID\", \"Description\", \"PetID\", \"Name\", \"VideoAmt\", \"PhotoAmt\",\n",
    "                                          \"Age\", \"Quantity\", \"Fee\", \"RescuerID_count\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1: data_all:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3445679455001793\n",
      "Kappa: 0.170580504512022\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>25</td>\n",
       "      <td>4</td>\n",
       "      <td>8</td>\n",
       "      <td>52</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>147</td>\n",
       "      <td>132</td>\n",
       "      <td>40</td>\n",
       "      <td>278</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>134</td>\n",
       "      <td>155</td>\n",
       "      <td>110</td>\n",
       "      <td>359</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>79</td>\n",
       "      <td>127</td>\n",
       "      <td>105</td>\n",
       "      <td>270</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>82</td>\n",
       "      <td>57</td>\n",
       "      <td>62</td>\n",
       "      <td>553</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>10</td>\n",
       "      <td>467</td>\n",
       "      <td>475</td>\n",
       "      <td>325</td>\n",
       "      <td>1512</td>\n",
       "      <td>2789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1    2    3     4   All\n",
       "Actual                                  \n",
       "0           1   25    4    8    52    90\n",
       "1           0  147  132   40   278   597\n",
       "2           4  134  155  110   359   762\n",
       "3           1   79  127  105   270   582\n",
       "4           4   82   57   62   553   758\n",
       "All        10  467  475  325  1512  2789"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train test 20%\n",
    "train, test = train_test_split(data_all, test_size=0.2, random_state=42, shuffle=True)\n",
    "X_train = train.drop(columns=[\"AdoptionSpeed\"])\n",
    "y_train = train[\"AdoptionSpeed\"]\n",
    "X_test = test.drop(columns=[\"AdoptionSpeed\"])\n",
    "y_test = test[\"AdoptionSpeed\"]\n",
    "\n",
    "# Run through model\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Kappa:\", cohen_kappa_score(y_test, y_pred, weights='quadratic'))\n",
    "pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:   11.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=GaussianNB(priors=None, var_smoothing=1e-09),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02,...\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(cohen_kappa_score, weights=quadratic),\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now do GridSearchCV on the model\n",
    "params = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "quadratic_kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "grid = GridSearchCV(GaussianNB(), params, refit = True, verbose = True, scoring=quadratic_kappa_scorer)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 3.5111917342151277e-07}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3607027608461814\n",
      "Kappa: 0.1976118079639656\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>7</td>\n",
       "      <td>6</td>\n",
       "      <td>49</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>177</td>\n",
       "      <td>140</td>\n",
       "      <td>44</td>\n",
       "      <td>234</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>155</td>\n",
       "      <td>188</td>\n",
       "      <td>104</td>\n",
       "      <td>315</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>91</td>\n",
       "      <td>130</td>\n",
       "      <td>105</td>\n",
       "      <td>254</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2</td>\n",
       "      <td>107</td>\n",
       "      <td>72</td>\n",
       "      <td>42</td>\n",
       "      <td>535</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>7</td>\n",
       "      <td>557</td>\n",
       "      <td>537</td>\n",
       "      <td>301</td>\n",
       "      <td>1387</td>\n",
       "      <td>2789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0    1    2    3     4   All\n",
       "Actual                                 \n",
       "0          1   27    7    6    49    90\n",
       "1          2  177  140   44   234   597\n",
       "2          0  155  188  104   315   762\n",
       "3          2   91  130  105   254   582\n",
       "4          2  107   72   42   535   758\n",
       "All        7  557  537  301  1387  2789"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run through model optimal\n",
    "gnb = GaussianNB(var_smoothing=3.5111917342151277e-07)\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Model Accuracy optimal\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Kappa:\", cohen_kappa_score(y_test, y_pred, weights='quadratic'))\n",
    "pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2: data_categorical:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Kappa: 0.20178287543869167\n",
      "Accuracy: 0.3363212621011115\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>141</td>\n",
       "      <td>310</td>\n",
       "      <td>40</td>\n",
       "      <td>105</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>134</td>\n",
       "      <td>411</td>\n",
       "      <td>59</td>\n",
       "      <td>158</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>88</td>\n",
       "      <td>276</td>\n",
       "      <td>63</td>\n",
       "      <td>153</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>84</td>\n",
       "      <td>304</td>\n",
       "      <td>45</td>\n",
       "      <td>322</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>7</td>\n",
       "      <td>474</td>\n",
       "      <td>1331</td>\n",
       "      <td>215</td>\n",
       "      <td>762</td>\n",
       "      <td>2789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0    1     2    3    4   All\n",
       "Actual                                 \n",
       "0          1   27    30    8   24    90\n",
       "1          1  141   310   40  105   597\n",
       "2          0  134   411   59  158   762\n",
       "3          2   88   276   63  153   582\n",
       "4          3   84   304   45  322   758\n",
       "All        7  474  1331  215  762  2789"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train test 20%\n",
    "train, test = train_test_split(data_categorical, test_size=0.2, random_state=42, shuffle=True)\n",
    "X_train = train.drop(columns=[\"AdoptionSpeed\"])\n",
    "y_train = train[\"AdoptionSpeed\"]\n",
    "X_test = test.drop(columns=[\"AdoptionSpeed\"])\n",
    "y_test = test[\"AdoptionSpeed\"]\n",
    "\n",
    "# Run through model\n",
    "gnb = GaussianNB()\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Kappa:\", cohen_kappa_score(y_test, y_pred, weights='quadratic'))\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 100 candidates, totalling 500 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done 500 out of 500 | elapsed:    3.3s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=GaussianNB(priors=None, var_smoothing=1e-09),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'var_smoothing': array([1.00000000e+00, 8.11130831e-01, 6.57933225e-01, 5.33669923e-01,\n",
       "       4.32876128e-01, 3.51119173e-01, 2.84803587e-01, 2.31012970e-01,\n",
       "       1.87381742e-01, 1.51991108e-01, 1.23284674e-01, 1.00000000e-01,\n",
       "       8.11130831e-02,...\n",
       "       2.31012970e-08, 1.87381742e-08, 1.51991108e-08, 1.23284674e-08,\n",
       "       1.00000000e-08, 8.11130831e-09, 6.57933225e-09, 5.33669923e-09,\n",
       "       4.32876128e-09, 3.51119173e-09, 2.84803587e-09, 2.31012970e-09,\n",
       "       1.87381742e-09, 1.51991108e-09, 1.23284674e-09, 1.00000000e-09])},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(cohen_kappa_score, weights=quadratic),\n",
       "             verbose=True)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now do GridSearchCV on the model\n",
    "params = {'var_smoothing': np.logspace(0,-9, num=100)}\n",
    "quadratic_kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "grid = GridSearchCV(GaussianNB(), params, refit = True, verbose = True, scoring=quadratic_kappa_scorer)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'var_smoothing': 6.579332246575682e-08}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.33381140193617787\n",
      "Kappa: 0.20163722884283353\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>30</td>\n",
       "      <td>8</td>\n",
       "      <td>24</td>\n",
       "      <td>90</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>133</td>\n",
       "      <td>318</td>\n",
       "      <td>40</td>\n",
       "      <td>105</td>\n",
       "      <td>597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>133</td>\n",
       "      <td>411</td>\n",
       "      <td>59</td>\n",
       "      <td>159</td>\n",
       "      <td>762</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>86</td>\n",
       "      <td>276</td>\n",
       "      <td>63</td>\n",
       "      <td>155</td>\n",
       "      <td>582</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>81</td>\n",
       "      <td>306</td>\n",
       "      <td>45</td>\n",
       "      <td>323</td>\n",
       "      <td>758</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>7</td>\n",
       "      <td>460</td>\n",
       "      <td>1341</td>\n",
       "      <td>215</td>\n",
       "      <td>766</td>\n",
       "      <td>2789</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted  0    1     2    3    4   All\n",
       "Actual                                 \n",
       "0          1   27    30    8   24    90\n",
       "1          1  133   318   40  105   597\n",
       "2          0  133   411   59  159   762\n",
       "3          2   86   276   63  155   582\n",
       "4          3   81   306   45  323   758\n",
       "All        7  460  1341  215  766  2789"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run through model v2\n",
    "gnb = GaussianNB(var_smoothing=6.579332246575682e-08)\n",
    "gnb.fit(X_train, y_train)\n",
    "y_pred = gnb.predict(X_test)\n",
    "\n",
    "# Model Accuracy v2\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Kappa:\", cohen_kappa_score(y_test, y_pred, weights='quadratic'))\n",
    "pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Multinomial NB with NLP\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize, word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer, PorterStemmer\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.decomposition import TruncatedSVD\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def transform_string_merge(df):\n",
    "    # This function turns all the relevent columns to their string counterparts and combines everything into one string\n",
    "    # First transform all the relevant numerical columns to strings\n",
    "    df[\"Type\"] = df[\"Type\"].apply(lambda x: \"Dog\" if x == 1 else \"Cat\")\n",
    "    \n",
    "    breed = pd.read_csv(\"/Users/Jinhao 1/Documents/git/COMP9417-GroupProject21T2/data/source/petfinder-adoption-prediction/BreedLabels.csv\")\n",
    "    breed_dict = dict(zip(breed[\"BreedID\"], breed[\"BreedName\"]))\n",
    "    df[\"Breed1\"] = df[\"Breed1\"].map(breed_dict)\n",
    "    df[\"Breed2\"] = df[\"Breed2\"].map(breed_dict)\n",
    "    \n",
    "    gender_dict = {1:\"Male\", 2:\"Female\", 3:\"Mixed\"}\n",
    "    df[\"Gender\"] = df[\"Gender\"].map(gender_dict)\n",
    "    \n",
    "    color = pd.read_csv(\"/Users/Jinhao 1/Documents/git/COMP9417-GroupProject21T2/data/source/petfinder-adoption-prediction/ColorLabels.csv\")\n",
    "    color_dict = dict(zip(color[\"ColorID\"], color[\"ColorName\"]))\n",
    "    df[\"Color1\"] = df[\"Color1\"].map(color_dict)\n",
    "    df[\"Color2\"] = df[\"Color2\"].map(color_dict)\n",
    "    df[\"Color3\"] = df[\"Color3\"].map(color_dict)\n",
    "    \n",
    "    maturity_dict = {1:\"Small\", 2:\"Medium\", 3:\"Large\", 4:\"Extra Large\", 0:\"Not Specified\"}\n",
    "    df[\"MaturitySize\"] = df[\"MaturitySize\"].map(maturity_dict)\n",
    "    \n",
    "    fur_dict = {1:\"Short\", 2:\"Medium\", 3:\"Long\", 0:\"Not Specified\"}\n",
    "    df[\"FurLength\"] = df[\"FurLength\"].map(fur_dict)\n",
    "\n",
    "    binary_dict = {1:\"Yes\", 2:\"No\", 3:\"Not Sure\"}\n",
    "    df[\"Vaccinated\"] = df[\"Vaccinated\"].map(binary_dict)\n",
    "    df[\"Dewormed\"] = df[\"Dewormed\"].map(binary_dict)\n",
    "    df[\"Sterilized\"] = df[\"Sterilized\"].map(binary_dict)\n",
    "\n",
    "    health_dict = {1:\"Healthy\", 2:\"Minor Injury\", 3:\"Serious Injury\", 0:\"Not Specified\"}\n",
    "    df[\"Health\"] = df[\"Health\"].map(health_dict)\n",
    "\n",
    "    state = pd.read_csv(\"/Users/Jinhao 1/Documents/git/COMP9417-GroupProject21T2/data/source/petfinder-adoption-prediction/StateLabels.csv\")\n",
    "    state_dict = dict(zip(state[\"StateID\"], state[\"StateName\"]))\n",
    "    df[\"State\"] = df[\"State\"].map(state_dict)\n",
    "\n",
    "    # More clean-up\n",
    "    df = df.fillna('')\n",
    "    df = df.where(pd.notnull(df), None)\n",
    "    \n",
    "    # Turn all columns into strings and then combine in new column as one string\n",
    "    all_columns = list(df) # Creates list of all column headers\n",
    "    df[all_columns] = df[all_columns].astype(str)\n",
    "    \n",
    "    # Combine all relevant columns as one string\n",
    "    df[\"x_string\"] = df[['Name', \n",
    "                         'Age', \n",
    "                         'Breed1', \n",
    "                         'Breed2', \n",
    "                         'Gender', \n",
    "                         'Color1', \n",
    "                         'Color2', \n",
    "                         'Color3', \n",
    "                         'MaturitySize', \n",
    "                         'FurLength', \n",
    "                         'Vaccinated', \n",
    "                         'Dewormed', \n",
    "                         'Sterilized', \n",
    "                         'Health', \n",
    "                         'Fee', \n",
    "                         'State', \n",
    "                         'Description']].agg(' '.join, axis=1)\n",
    "    \n",
    "    df = df[df.x_string.map(lambda x: x.isascii())]\n",
    "    df_new = df[[\"x_string\", \"AdoptionSpeed\"]]\n",
    "    \n",
    "    return df_new"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize(data):\n",
    "    tokenized_docs = [word_tokenize(doc) for doc in data]\n",
    "    alpha_tokens = [[t.lower() for t in doc if t.isalpha() == True] for doc in tokenized_docs]\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    lem_tokens = [[lemmatizer.lemmatize(alpha) for alpha in doc] for doc in alpha_tokens]\n",
    "    X_stem_as_string = [\" \".join(x_t) for x_t in lem_tokens]\n",
    "    return X_stem_as_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_TABULAR)\n",
    "\n",
    "# Use transform function\n",
    "df_transformed = transform_string_merge(df)\n",
    "\n",
    "# Split processed df into train and split\n",
    "train, test = train_test_split(df_transformed, test_size=0.2, random_state=42, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "vct = CountVectorizer(stop_words='english', lowercase=False)\n",
    "svd = TruncatedSVD(n_components=200, random_state=42)\n",
    "tfvec = TfidfVectorizer(stop_words='english', ngram_range=(1, 2), lowercase=False)\n",
    "\n",
    "preprocessing_pipe = Pipeline([\n",
    "    ('vectorizer', tfvec),\n",
    "    ('svd', svd)   \n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_tk = tokenize(train[\"x_string\"])\n",
    "X_test_tk = tokenize(test[\"x_string\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11438, 200)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lsa_train = preprocessing_pipe.fit_transform(X_train_tk)\n",
    "lsa_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.39090909090909093\n",
      "Kappa: 0.2177138737405876\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00        70\n",
      "           1       0.46      0.04      0.07       583\n",
      "           2       0.36      0.55      0.43       779\n",
      "           3       0.62      0.07      0.13       645\n",
      "           4       0.40      0.79      0.54       783\n",
      "\n",
      "    accuracy                           0.39      2860\n",
      "   macro avg       0.37      0.29      0.23      2860\n",
      "weighted avg       0.44      0.39      0.31      2860\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/sklearn/metrics/_classification.py:1272: UndefinedMetricWarning: Precision and F-score are ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    }
   ],
   "source": [
    "# Multinomial NB\n",
    "mb = MultinomialNB(alpha=1)\n",
    "pipe = Pipeline([\n",
    "    ('vectorizer', tfvec),\n",
    "    ('mb', mb)\n",
    "])\n",
    "pipe.fit(X_train_tk, train[\"AdoptionSpeed\"])\n",
    "y_pred = pipe.predict(X_test_tk)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Accuracy:\", accuracy_score(test[\"AdoptionSpeed\"], y_pred))\n",
    "print(\"Kappa:\", cohen_kappa_score(test[\"AdoptionSpeed\"], y_pred, weights='quadratic'))\n",
    "print(classification_report(test[\"AdoptionSpeed\"], y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Multinomial NB with one-hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_TABULAR)\n",
    "\n",
    "transformed_df = df.copy()\n",
    "\n",
    "# Change Name to 1 - has name, 0 - has no name\n",
    "transformed_df['Name'] = transformed_df['Name'].fillna(0)\n",
    "transformed_df['Name'].replace({\"No Name\": 0, \"No Name Yet\": 0, \"Unknown\": 0},inplace=True)\n",
    "transformed_df.loc[transformed_df['Name'] !=0, 'Name'] = 1\n",
    "\n",
    "# RescuerID Counts\n",
    "rescuerid_counts = pd.DataFrame(transformed_df.groupby([\"RescuerID\"]).size(), columns=[\"RescuerID_Count\"]).reset_index()\n",
    "transformed_df = pd.merge(transformed_df, rescuerid_counts, on=\"RescuerID\")\n",
    "\n",
    "# create age bins\n",
    "age_bins = pd.cut(transformed_df['Age'], bins=[0,3,6,12,24,300], include_lowest=True)\n",
    "age_bin_dummies = pd.get_dummies(age_bins)\n",
    "age_bin_dummies.columns = [\"is_age_0_3\", \"is_age_3_6\", \"is_age_6_12\",\"is_age_12_24\", \"is_age_24_300\"]\n",
    "transformed_df = pd.concat([transformed_df, age_bin_dummies], axis=1)\n",
    "\n",
    "# one-hot encode dummy variables\n",
    "\n",
    "dummy_cols = [\n",
    "    'Type',\n",
    "    'Gender',\n",
    "    'MaturitySize',\n",
    "    'Vaccinated',\n",
    "    'Dewormed',\n",
    "    'Sterilized',\n",
    "    'Health',\n",
    "    'FurLength',\n",
    "    'State',\n",
    "    'Breed1',\n",
    "    'Breed2',\n",
    "    'Color1',\n",
    "    'Color2',\n",
    "    'Color3',\n",
    "]\n",
    "\n",
    "transformed_df = pd.get_dummies(transformed_df, columns=dummy_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.drop(columns=[\"VideoAmt\", \"PhotoAmt\", \"RescuerID\", \"Description\", \"PetID\",\n",
    "                             \"Age\", \"Fee\", \"RescuerID_Count\"], inplace=True)\n",
    "\n",
    "# Included - Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35978659553184394\n",
      "Kappa: 0.2562594914543773\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>16</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>206</td>\n",
       "      <td>208</td>\n",
       "      <td>70</td>\n",
       "      <td>132</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>193</td>\n",
       "      <td>298</td>\n",
       "      <td>89</td>\n",
       "      <td>225</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>121</td>\n",
       "      <td>222</td>\n",
       "      <td>116</td>\n",
       "      <td>185</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>114</td>\n",
       "      <td>181</td>\n",
       "      <td>83</td>\n",
       "      <td>458</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>18</td>\n",
       "      <td>664</td>\n",
       "      <td>929</td>\n",
       "      <td>372</td>\n",
       "      <td>1016</td>\n",
       "      <td>2999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1    2    3     4   All\n",
       "Actual                                  \n",
       "0           1   30   20   14    16    81\n",
       "1           2  206  208   70   132   618\n",
       "2           5  193  298   89   225   810\n",
       "3           5  121  222  116   185   649\n",
       "4           5  114  181   83   458   841\n",
       "All        18  664  929  372  1016  2999"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split into train test 20%\n",
    "train, test = train_test_split(transformed_df, test_size=0.2, random_state=42, shuffle=True)\n",
    "X_train = train.drop(columns=[\"AdoptionSpeed\"])\n",
    "y_train = train[\"AdoptionSpeed\"]\n",
    "X_test = test.drop(columns=[\"AdoptionSpeed\"])\n",
    "y_test = test[\"AdoptionSpeed\"]\n",
    "\n",
    "# Run through model\n",
    "clf_all = MultinomialNB(alpha=1)\n",
    "clf_all.fit(X_train, y_train)\n",
    "y_pred = clf_all.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Kappa:\", cohen_kappa_score(y_test, y_pred, weights='quadratic'))\n",
    "pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] alpha=0.01 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... alpha=0.01, score=0.261, total=   0.3s\n",
      "[CV] alpha=0.01 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... alpha=0.01, score=0.279, total=   0.2s\n",
      "[CV] alpha=0.01 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... alpha=0.01, score=0.243, total=   0.2s\n",
      "[CV] alpha=0.01 ......................................................\n",
      "[CV] .......................... alpha=0.01, score=0.279, total=   0.3s\n",
      "[CV] alpha=0.01 ......................................................\n",
      "[CV] .......................... alpha=0.01, score=0.286, total=   0.3s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ........................... alpha=0.1, score=0.259, total=   0.2s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ........................... alpha=0.1, score=0.278, total=   0.2s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ........................... alpha=0.1, score=0.246, total=   0.2s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ........................... alpha=0.1, score=0.282, total=   0.2s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ........................... alpha=0.1, score=0.283, total=   0.2s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] ........................... alpha=0.5, score=0.259, total=   0.2s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] ........................... alpha=0.5, score=0.270, total=   0.2s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] ........................... alpha=0.5, score=0.249, total=   0.2s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] ........................... alpha=0.5, score=0.285, total=   0.2s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] ........................... alpha=0.5, score=0.279, total=   0.2s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] ........................... alpha=1.0, score=0.254, total=   0.3s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] ........................... alpha=1.0, score=0.274, total=   0.3s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] ........................... alpha=1.0, score=0.240, total=   0.4s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] ........................... alpha=1.0, score=0.283, total=   0.4s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] ........................... alpha=1.0, score=0.275, total=   0.3s\n",
      "[CV] alpha=10.0 ......................................................\n",
      "[CV] .......................... alpha=10.0, score=0.242, total=   0.3s\n",
      "[CV] alpha=10.0 ......................................................\n",
      "[CV] .......................... alpha=10.0, score=0.242, total=   0.3s\n",
      "[CV] alpha=10.0 ......................................................\n",
      "[CV] .......................... alpha=10.0, score=0.221, total=   0.3s\n",
      "[CV] alpha=10.0 ......................................................\n",
      "[CV] .......................... alpha=10.0, score=0.242, total=   0.3s\n",
      "[CV] alpha=10.0 ......................................................\n",
      "[CV] .......................... alpha=10.0, score=0.259, total=   0.3s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    6.9s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
       "                                     fit_prior=True),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'alpha': [0.01, 0.1, 0.5, 1.0, 10.0]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(cohen_kappa_score, weights=quadratic),\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now do GridSearchCV on the model\n",
    "params = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0, ], }\n",
    "quadratic_kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "grid = GridSearchCV(MultinomialNB(), params, refit = True, verbose = 3, scoring=quadratic_kappa_scorer)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.3567855951983995\n",
      "Kappa: 0.25695836024345053\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>20</td>\n",
       "      <td>16</td>\n",
       "      <td>15</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8</td>\n",
       "      <td>203</td>\n",
       "      <td>206</td>\n",
       "      <td>75</td>\n",
       "      <td>126</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5</td>\n",
       "      <td>194</td>\n",
       "      <td>291</td>\n",
       "      <td>97</td>\n",
       "      <td>223</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>124</td>\n",
       "      <td>213</td>\n",
       "      <td>125</td>\n",
       "      <td>185</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7</td>\n",
       "      <td>116</td>\n",
       "      <td>178</td>\n",
       "      <td>89</td>\n",
       "      <td>451</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>22</td>\n",
       "      <td>667</td>\n",
       "      <td>908</td>\n",
       "      <td>402</td>\n",
       "      <td>1000</td>\n",
       "      <td>2999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1    2    3     4   All\n",
       "Actual                                  \n",
       "0           0   30   20   16    15    81\n",
       "1           8  203  206   75   126   618\n",
       "2           5  194  291   97   223   810\n",
       "3           2  124  213  125   185   649\n",
       "4           7  116  178   89   451   841\n",
       "All        22  667  908  402  1000  2999"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run through model v2\n",
    "clf_all = MultinomialNB(alpha=0.1)\n",
    "clf_all.fit(X_train, y_train)\n",
    "y_pred = clf_all.predict(X_test)\n",
    "\n",
    "# Model Accuracy v2\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Kappa:\", cohen_kappa_score(y_test, y_pred, weights='quadratic'))\n",
    "pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Bernoulli NB with one-hot encoding\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    " from sklearn.naive_bayes import BernoulliNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv(TRAIN_TABULAR)\n",
    "\n",
    "transformed_df = df.copy()\n",
    "\n",
    "# Change Name to 1 - has name, 0 - has no name\n",
    "transformed_df['Name'] = transformed_df['Name'].fillna(0)\n",
    "transformed_df['Name'].replace({\"No Name\": 0, \"No Name Yet\": 0, \"Unknown\": 0},inplace=True)\n",
    "transformed_df.loc[transformed_df['Name'] !=0, 'Name'] = 1\n",
    "\n",
    "# RescuerID Counts\n",
    "rescuerid_counts = pd.DataFrame(transformed_df.groupby([\"RescuerID\"]).size(), columns=[\"RescuerID_Count\"]).reset_index()\n",
    "transformed_df = pd.merge(transformed_df, rescuerid_counts, on=\"RescuerID\")\n",
    "\n",
    "# create age bins\n",
    "age_bins = pd.cut(transformed_df['Age'], bins=[0,3,6,12,24,300], include_lowest=True)\n",
    "age_bin_dummies = pd.get_dummies(age_bins)\n",
    "age_bin_dummies.columns = [\"is_age_0_3\", \"is_age_3_6\", \"is_age_6_12\",\"is_age_12_24\", \"is_age_24_300\"]\n",
    "transformed_df = pd.concat([transformed_df, age_bin_dummies], axis=1)\n",
    "\n",
    "# one-hot encode dummy variables\n",
    "\n",
    "dummy_cols = [\n",
    "    'Type',\n",
    "    'Gender',\n",
    "    'MaturitySize',\n",
    "    'Vaccinated',\n",
    "    'Dewormed',\n",
    "    'Sterilized',\n",
    "    'Health',\n",
    "    'FurLength',\n",
    "    'State',\n",
    "    'Breed1',\n",
    "    'Breed2',\n",
    "    'Color1',\n",
    "    'Color2',\n",
    "    'Color3',\n",
    "]\n",
    "\n",
    "transformed_df = pd.get_dummies(transformed_df, columns=dummy_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "transformed_df.drop(columns=[\"VideoAmt\", \"PhotoAmt\", \"RescuerID\", \"Description\", \"PetID\",\n",
    "                             \"Age\", \"Fee\", \"RescuerID_Count\"], inplace=True)\n",
    "\n",
    "# Included - Quantity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.36178726242080694\n",
      "Kappa: 0.23784268585208956\n"
     ]
    }
   ],
   "source": [
    "# Split into train test 20%\n",
    "train, test = train_test_split(transformed_df, test_size=0.2, random_state=42, shuffle=True)\n",
    "X_train = train.drop(columns=[\"AdoptionSpeed\"])\n",
    "y_train = train[\"AdoptionSpeed\"]\n",
    "X_test = test.drop(columns=[\"AdoptionSpeed\"])\n",
    "y_test = test[\"AdoptionSpeed\"]\n",
    "\n",
    "# Run through model\n",
    "clf_all = BernoulliNB(alpha=1)\n",
    "clf_all.fit(X_train, y_train)\n",
    "y_pred = clf_all.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)\n",
    "print(\"Kappa:\", cohen_kappa_score(y_test, y_pred, weights='quadratic'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 5 candidates, totalling 25 fits\n",
      "[CV] alpha=0.01 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... alpha=0.01, score=0.261, total=   0.3s\n",
      "[CV] alpha=0.01 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.3s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... alpha=0.01, score=0.279, total=   0.2s\n",
      "[CV] alpha=0.01 ......................................................\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done   2 out of   2 | elapsed:    0.5s remaining:    0.0s\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[CV] .......................... alpha=0.01, score=0.243, total=   0.3s\n",
      "[CV] alpha=0.01 ......................................................\n",
      "[CV] .......................... alpha=0.01, score=0.279, total=   0.5s\n",
      "[CV] alpha=0.01 ......................................................\n",
      "[CV] .......................... alpha=0.01, score=0.286, total=   0.3s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ........................... alpha=0.1, score=0.259, total=   0.2s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ........................... alpha=0.1, score=0.278, total=   0.2s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ........................... alpha=0.1, score=0.246, total=   0.3s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ........................... alpha=0.1, score=0.282, total=   0.2s\n",
      "[CV] alpha=0.1 .......................................................\n",
      "[CV] ........................... alpha=0.1, score=0.283, total=   0.2s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] ........................... alpha=0.5, score=0.259, total=   0.2s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] ........................... alpha=0.5, score=0.270, total=   0.2s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] ........................... alpha=0.5, score=0.249, total=   0.2s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] ........................... alpha=0.5, score=0.285, total=   0.2s\n",
      "[CV] alpha=0.5 .......................................................\n",
      "[CV] ........................... alpha=0.5, score=0.279, total=   0.2s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] ........................... alpha=1.0, score=0.254, total=   0.2s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] ........................... alpha=1.0, score=0.274, total=   0.2s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] ........................... alpha=1.0, score=0.240, total=   0.3s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] ........................... alpha=1.0, score=0.283, total=   0.2s\n",
      "[CV] alpha=1.0 .......................................................\n",
      "[CV] ........................... alpha=1.0, score=0.275, total=   0.2s\n",
      "[CV] alpha=10.0 ......................................................\n",
      "[CV] .......................... alpha=10.0, score=0.242, total=   0.2s\n",
      "[CV] alpha=10.0 ......................................................\n",
      "[CV] .......................... alpha=10.0, score=0.242, total=   0.2s\n",
      "[CV] alpha=10.0 ......................................................\n",
      "[CV] .......................... alpha=10.0, score=0.221, total=   0.2s\n",
      "[CV] alpha=10.0 ......................................................\n",
      "[CV] .......................... alpha=10.0, score=0.242, total=   0.2s\n",
      "[CV] alpha=10.0 ......................................................\n",
      "[CV] .......................... alpha=10.0, score=0.259, total=   0.2s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Done  25 out of  25 | elapsed:    6.4s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=None, error_score=nan,\n",
       "             estimator=MultinomialNB(alpha=1.0, class_prior=None,\n",
       "                                     fit_prior=True),\n",
       "             iid='deprecated', n_jobs=None,\n",
       "             param_grid={'alpha': [0.01, 0.1, 0.5, 1.0, 10.0]},\n",
       "             pre_dispatch='2*n_jobs', refit=True, return_train_score=False,\n",
       "             scoring=make_scorer(cohen_kappa_score, weights=quadratic),\n",
       "             verbose=3)"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Now do GridSearchCV on the model\n",
    "params = {'alpha': [0.01, 0.1, 0.5, 1.0, 10.0, ], }\n",
    "quadratic_kappa_scorer = make_scorer(cohen_kappa_score, weights='quadratic')\n",
    "grid = GridSearchCV(MultinomialNB(), params, refit = True, verbose = 3, scoring=quadratic_kappa_scorer)\n",
    "\n",
    "grid.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'alpha': 0.1}\n"
     ]
    }
   ],
   "source": [
    "print(grid.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.35745248416138714\n",
      "Kappa: 0.24366698325412572\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Predicted</th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>All</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Actual</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>29</td>\n",
       "      <td>17</td>\n",
       "      <td>14</td>\n",
       "      <td>18</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15</td>\n",
       "      <td>236</td>\n",
       "      <td>161</td>\n",
       "      <td>77</td>\n",
       "      <td>129</td>\n",
       "      <td>618</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>11</td>\n",
       "      <td>225</td>\n",
       "      <td>256</td>\n",
       "      <td>106</td>\n",
       "      <td>212</td>\n",
       "      <td>810</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>6</td>\n",
       "      <td>149</td>\n",
       "      <td>167</td>\n",
       "      <td>133</td>\n",
       "      <td>194</td>\n",
       "      <td>649</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>15</td>\n",
       "      <td>147</td>\n",
       "      <td>148</td>\n",
       "      <td>87</td>\n",
       "      <td>444</td>\n",
       "      <td>841</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>All</th>\n",
       "      <td>50</td>\n",
       "      <td>786</td>\n",
       "      <td>749</td>\n",
       "      <td>417</td>\n",
       "      <td>997</td>\n",
       "      <td>2999</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "Predicted   0    1    2    3    4   All\n",
       "Actual                                 \n",
       "0           3   29   17   14   18    81\n",
       "1          15  236  161   77  129   618\n",
       "2          11  225  256  106  212   810\n",
       "3           6  149  167  133  194   649\n",
       "4          15  147  148   87  444   841\n",
       "All        50  786  749  417  997  2999"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run through model\n",
    "clf_all = BernoulliNB(alpha=0.1)\n",
    "clf_all.fit(X_train, y_train)\n",
    "y_pred = clf_all.predict(X_test)\n",
    "\n",
    "# Model Accuracy\n",
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(\"Kappa:\", cohen_kappa_score(y_test, y_pred, weights='quadratic'))\n",
    "pd.crosstab(y_test, y_pred, rownames=['Actual'], colnames=['Predicted'], margins=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
